<!DOCTYPE html>
<!-- saved from url=(0070)https://www.arunponnusamy.com/yolo-object-detection-opencv-python.html -->
<html class="gr__arunponnusamy_com"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1.0">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script type="text/javascript" async="" src="./YOLO Object Detection with OpenCV and Python_files/analytics.js"></script><script async="" src="./YOLO Object Detection with OpenCV and Python_files/js"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-115491079-1');
</script>

    <title>YOLO Object Detection with OpenCV and Python</title>
    <meta name="description" content="Object detection using OpenCV dnn module with a pre-trained YOLO v3 model with Python. Detect 80 common objects in context including car, bike, dog, cat etc.">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="arunponnusamy.com">
    <meta name="twitter:creator" content="@ponnusamy_arun">
    <meta name="twitter:image:src" content="http://www.arunponnusamy.com/images/yolo-object-detection-opencv-python/yolo-object-detection.jpg">

    
    <meta property="og:title" content="YOLO Object Detection with OpenCV and Python">
    <meta property="og:image" content="images/yolo-object-detection-opencv-python/yolo-object-detection.jpg">
    <meta property="og:description" content="Object detection using OpenCV dnn module with a pre-trained YOLO v3 model with Python. Detect 80 common objects in context including car, bike, dog, cat etc. ">
    <meta property="og:url" content="arunponnusamy.com">

    <link rel="stylesheet" type="text/css" href="./YOLO Object Detection with OpenCV and Python_files/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="./YOLO Object Detection with OpenCV and Python_files/main.css">
    
  <link rel="stylesheet" href="./YOLO Object Detection with OpenCV and Python_files/css">
<script src="./YOLO Object Detection with OpenCV and Python_files/embed.js" data-timestamp="1553629543835"></script><style type="text/css" id="parrottalks-notetaker-style">      html > body.evernote_clearly__before_visible #parrottalks-notetaker > iframe,      html > body.clearlyBeforeVisible #parrottalks-notetaker > iframe:not(#evernoteGlobalTools):not(#evernoteOptionsPage):not(#evernoteClearlyArticle) {        visibility: visible !important;      }      .evernote_clearly__before_visible #evernote_clearly__reformat,      .clearlyBeforeVisible #evernoteClearlyArticle {        z-index: 2147483646 !important;      }    </style><link rel="preload" as="style" href="https://c.disquscdn.com/next/embed/styles/lounge.9974049bf7b0591e5d4f055cb67f3ee3.css"><link rel="preload" as="script" href="https://c.disquscdn.com/next/embed/common.bundle.880980e048a2432334f13013030456ac.js"><link rel="preload" as="script" href="https://c.disquscdn.com/next/embed/lounge.bundle.4180262f1aa52e0f0340aac9fc52a8d8.js"><link rel="preload" as="script" href="https://disqus.com/next/config.js"><script src="./YOLO Object Detection with OpenCV and Python_files/alfie.f51946af45e0b561c60f768335c9eb79.js" async="" charset="UTF-8"></script></head>

<body data-gr-c-s-loaded="true">

<header>
    <div class="container">
        <div class="row">
            <h2 class="col-sm-offset-2 col-sm-4 text-left">
            <a href="https://www.arunponnusamy.com/index.html">Arun Ponnusamy</a></h2>
            <nav class="col-sm-6 text-right">
            <h3>
            <a href="https://www.arunponnusamy.com/index.html">Home</a></h3>
            <h3>
            <a href="https://www.arunponnusamy.com/about.html">About</a></h3>
            <h3>
            <a href="https://www.arunponnusamy.com/ArunPonnusamy-CV.pdf">CV</a></h3>
            <h3>
            <a href="https://www.arunponnusamy.com/contact.html">Contact</a></h3>            
            </nav>
        </div>
    </div>
</header>

<section>
    <div>
        <h1 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">YOLO Object Detection with OpenCV and Python</h1>
	<p id="author" class="col-sm-offset-3 col-sm-6 col-sm-offset-3">28 Jul 2018 Arun Ponnusamy</p><p>
        <img class="col-sm-offset-4 col-sm-4 col-sm-offset-4" src="./YOLO Object Detection with OpenCV and Python_files/yolo-object-detection.jpg">
        </p><p class="col-sm-offset-4 col-sm-4 col-sm-offset-4" id="source">Image Source: <a href="https://github.com/pjreddie/darknet/blob/master/data/dog.jpg">DarkNet github repo</a></p>
	
	<p></p>
	<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">If you have been keeping up with the advancements in the area of object detection, you might have got used to hearing this word 'YOLO'. It has kind of become a buzzword.</p>

<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">What is YOLO&nbsp;exactly?</h2>


	<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">YOLO (You Only Look Once) is a method / way to do object detection. It is the algorithm /strategy behind how the code is going to detect objects in the image.</p>

	<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">The official implementation of this idea is available through <a href="https://pjreddie.com/darknet/">DarkNet</a> (neural net implementation from the ground up in 'C' from the author). It is available on <a href"https:="" github.com="" pjreddie="" darknet"="">github</a> for people to use.</p>
		
	<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Earlier detection frameworks, looked at different parts of the image multiple times at different scales and repurposed image classification technique to detect objects. This approach is slow and inefficient.</p>
	
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">YOLO takes entirely different approach. It looks at the entire image only once and goes through the network once and detects objects. Hence the name. It is very fast. That’s the reason it has got so popular. </p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">There are other popular object detection frameworks like <b>Faster R-CNN</b> and <b>SSD</b> that are also widely used. </p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">In this post, we are going to look at how to use a pre-trained YOLO model with OpenCV and start detecting objects right away.</p>

	<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3 text-center">.    .    .</p>
		
<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">OpenCV dnn module</h2>
     
	<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">DNN (Deep Neural Network) module was initially part of <code>opencv_contrib</code> repo. It has been moved to the master branch of <code>opencv</code> repo last year, giving users the ability to run inference on pre-trained deep learning models within OpenCV itself. </p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">(One thing to note here is, <code>dnn</code> module is not meant be used for training. It’s just for running inference on images/videos.)</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Initially only Caffe and Torch models were supported. Over the period support for different frameworks/libraries like TensorFlow is being added. </p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Support for YOLO/DarkNet has been added recently. We are going to use the OpenCV dnn module with a pre-trained YOLO model for detecting common objects.</p>

<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Let’s get started ..</h2>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Enough of talking. Let’s start writing code. (in Python obviously)</p>

<div class="col-sm-offset-3 col-sm-6 col-sm-offset-3">
<script src="./YOLO Object Detection with OpenCV and Python_files/263037b45089e8510c126beae63e75eb.js"></script><link rel="stylesheet" href="./YOLO Object Detection with OpenCV and Python_files/gist-embed-a9a1cf2ca01efd362bfa52312712ae94.css"><div id="gist90947254" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-yolo_opencv_part1-py" class="file">
    

  <div itemprop="text" class="Box-body px-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-yolo_opencv_part1-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-yolo_opencv_part1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> import required packages</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-yolo_opencv_part1-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> cv2</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-yolo_opencv_part1-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> argparse</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-yolo_opencv_part1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> numpy <span class="pl-k">as</span> np</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-yolo_opencv_part1-py-LC5" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-yolo_opencv_part1-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> handle command line arguments</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-yolo_opencv_part1-py-LC7" class="blob-code blob-code-inner js-file-line">ap <span class="pl-k">=</span> argparse.ArgumentParser()</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-yolo_opencv_part1-py-LC8" class="blob-code blob-code-inner js-file-line">ap.add_argument(<span class="pl-s"><span class="pl-pds">'</span>-i<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span>--image<span class="pl-pds">'</span></span>, <span class="pl-v">required</span><span class="pl-k">=</span><span class="pl-c1">True</span>,</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-yolo_opencv_part1-py-LC9" class="blob-code blob-code-inner js-file-line">                <span class="pl-v">help</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>path to input image<span class="pl-pds">'</span></span>)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-yolo_opencv_part1-py-LC10" class="blob-code blob-code-inner js-file-line">ap.add_argument(<span class="pl-s"><span class="pl-pds">'</span>-c<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span>--config<span class="pl-pds">'</span></span>, <span class="pl-v">required</span><span class="pl-k">=</span><span class="pl-c1">True</span>,</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-yolo_opencv_part1-py-LC11" class="blob-code blob-code-inner js-file-line">                <span class="pl-v">help</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>path to yolo config file<span class="pl-pds">'</span></span>)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-yolo_opencv_part1-py-LC12" class="blob-code blob-code-inner js-file-line">ap.add_argument(<span class="pl-s"><span class="pl-pds">'</span>-w<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span>--weights<span class="pl-pds">'</span></span>, <span class="pl-v">required</span><span class="pl-k">=</span><span class="pl-c1">True</span>,</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-yolo_opencv_part1-py-LC13" class="blob-code blob-code-inner js-file-line">                <span class="pl-v">help</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>path to yolo pre-trained weights<span class="pl-pds">'</span></span>)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-yolo_opencv_part1-py-LC14" class="blob-code blob-code-inner js-file-line">ap.add_argument(<span class="pl-s"><span class="pl-pds">'</span>-cl<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span>--classes<span class="pl-pds">'</span></span>, <span class="pl-v">required</span><span class="pl-k">=</span><span class="pl-c1">True</span>,</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L15" class="blob-num js-line-number" data-line-number="15"></td>
        <td id="file-yolo_opencv_part1-py-LC15" class="blob-code blob-code-inner js-file-line">                <span class="pl-v">help</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">'</span>path to text file containing class names<span class="pl-pds">'</span></span>)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part1-py-L16" class="blob-num js-line-number" data-line-number="16"></td>
        <td id="file-yolo_opencv_part1-py-LC16" class="blob-code blob-code-inner js-file-line">args <span class="pl-k">=</span> ap.parse_args()</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/arunponnusamy/263037b45089e8510c126beae63e75eb/raw/79578bad1f818d95ea0b47028d90bb6dd6d5df27/yolo_opencv_part1.py" style="float:right">view raw</a>
        <a href="https://gist.github.com/arunponnusamy/263037b45089e8510c126beae63e75eb#file-yolo_opencv_part1-py">yolo_opencv_part1.py</a>
        hosted with ❤ by <a href="https://github.com/">GitHub</a>
      </div>
    </div>
</div>
</div>

<h3 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Installing dependencies</h3>
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Following things are needed to execute the code we will be writing.</p>

<ul class="col-sm-offset-4 col-sm-4 col-sm-offset-4">
            <li>Python 3</li>
	    <li> Numpy </li>
	    <li> OpenCV Python bindings</li>

</ul>

<h3 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Python 3</h3>


<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">If you are on Ubuntu, it’s most likely that Python 3 is already installed. Run <code>python3</code> in terminal to check whether its installed. If its not installed use</p>

<code class="col-sm-offset-3 col-sm-6 col-sm-offset-3">sudo apt-get install python3</code>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">For macOS please refer my earlier post on <a href="http://www.arunponnusamy.com/deep-learning-setup-macos.html">deep learning setup for macOS</a>.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">I highly recommend using Python <b>virtual environment</b>. Have a look at my earlier  <a href="http://www.arunponnusamy.com/deep-learning-setup-macos.html">post</a> if you need a starting point.</p>

<h3 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Numpy</h3>
<code class="col-sm-offset-3 col-sm-6 col-sm-offset-3">pip install numpy</code>


<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">This should install <code>numpy</code>. Make sure <code>pip</code> is linked to Python 3.x ( <code>pip -V</code> will show this info)</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">If needed use <code>pip3</code>. Use <code>sudo apt-get install python3-pip</code> to get <code>pip3</code> if not already installed.</p>

<h3 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">OpenCV-Python</h3>
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">You need to compile OpenCV from source from the master branch on <a href="https://github.com/opencv/opencv">github</a> to get the Python bindings. (recommended)</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Adrian Rosebrock has written a good blog post on <a href="https://www.pyimagesearch.com/2017/09/25/configuring-ubuntu-for-deep-learning-with-python/">PyImageSearch</a> on this. (Download the source from master branch instead of from archive) </p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">If you are feeling overwhelmed by the instructions to get OpenCV Python bindings from source, you can get the unofficial Python package using </p>

<code class="col-sm-offset-3 col-sm-6 col-sm-offset-3"> pip install opencv-python </code>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">This is not maintained officially by <a href="https://www.arunponnusamy.com/opencv.org">OpenCV.org</a>. It’s a community maintained one. Thanks to the efforts of <a href="https://www.arunponnusamy.com/github.com/skvark">Olli-Pekka Heinisuo</a>. </p>

<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Command line arguments</h2>
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">The script requires four input arguments.</p>
<ul class="col-sm-offset-4 col-sm-4 col-sm-offset-4">
            <li>input image</li>
	    <li>YOLO config file</li>
	    <li>pre-trained YOLO weights </li>
	    <li>text file containing class names </li>

</ul>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">All of these files are available on the <a href="https://github.com/arunponnusamy/object-detection-opencv">github</a> repository I have put together. (link to download pre-trained weights is available in readme.)</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">You can also download the pre-trained weights in Terminal by typing</p>

<code class="col-sm-offset-3 col-sm-6 col-sm-offset-3">wget https://pjreddie.com/media/files/yolov3.weights</code>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">This particular model is trained on COCO dataset (common objects in context) from Microsoft. It is capable of detecting 80 common objects. See the full list <a href="https://github.com/arunponnusamy/object-detection-opencv/blob/master/yolov3.txt">here</a>.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Input image can be of your choice. Sample input is available in the <a href="https://github.com/arunponnusamy/object-detection-opencv">repo</a>.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Run the script by typing</p>

<code class="col-sm-offset-3 col-sm-6 col-sm-offset-3">$ python yolo_opencv.py --image dog.jpg --config yolov3.cfg --weights yolov3.weights --classes yolov3.txt </code>


<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Preparing input</h2>

<div class="col-sm-offset-3 col-sm-6 col-sm-offset-3">
<script src="./YOLO Object Detection with OpenCV and Python_files/64a0fcec27fea6abf3ac9f26485b9d6c.js"></script><link rel="stylesheet" href="./YOLO Object Detection with OpenCV and Python_files/gist-embed-a9a1cf2ca01efd362bfa52312712ae94.css"><div id="gist90993056" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-yolo_opencv_part2-py" class="file">
    

  <div itemprop="text" class="Box-body px-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-yolo_opencv_part2-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-yolo_opencv_part2-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> read input image</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-yolo_opencv_part2-py-LC2" class="blob-code blob-code-inner js-file-line">image <span class="pl-k">=</span> cv2.imread(args.image)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-yolo_opencv_part2-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-yolo_opencv_part2-py-LC4" class="blob-code blob-code-inner js-file-line">Width <span class="pl-k">=</span> image.shape[<span class="pl-c1">1</span>]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-yolo_opencv_part2-py-LC5" class="blob-code blob-code-inner js-file-line">Height <span class="pl-k">=</span> image.shape[<span class="pl-c1">0</span>]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-yolo_opencv_part2-py-LC6" class="blob-code blob-code-inner js-file-line">scale <span class="pl-k">=</span> <span class="pl-c1">0.00392</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-yolo_opencv_part2-py-LC7" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-yolo_opencv_part2-py-LC8" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> read class names from text file</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-yolo_opencv_part2-py-LC9" class="blob-code blob-code-inner js-file-line">classes <span class="pl-k">=</span> <span class="pl-c1">None</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-yolo_opencv_part2-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-k">with</span> <span class="pl-c1">open</span>(args.classes, <span class="pl-s"><span class="pl-pds">'</span>r<span class="pl-pds">'</span></span>) <span class="pl-k">as</span> f:</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-yolo_opencv_part2-py-LC11" class="blob-code blob-code-inner js-file-line">    classes <span class="pl-k">=</span> [line.strip() <span class="pl-k">for</span> line <span class="pl-k">in</span> f.readlines()]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-yolo_opencv_part2-py-LC12" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-yolo_opencv_part2-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> generate different colors for different classes </span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-yolo_opencv_part2-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-c1">COLORS</span> <span class="pl-k">=</span> np.random.uniform(<span class="pl-c1">0</span>, <span class="pl-c1">255</span>, <span class="pl-v">size</span><span class="pl-k">=</span>(<span class="pl-c1">len</span>(classes), <span class="pl-c1">3</span>))</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L15" class="blob-num js-line-number" data-line-number="15"></td>
        <td id="file-yolo_opencv_part2-py-LC15" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L16" class="blob-num js-line-number" data-line-number="16"></td>
        <td id="file-yolo_opencv_part2-py-LC16" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> read pre-trained model and config file</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L17" class="blob-num js-line-number" data-line-number="17"></td>
        <td id="file-yolo_opencv_part2-py-LC17" class="blob-code blob-code-inner js-file-line">net <span class="pl-k">=</span> cv2.dnn.readNet(args.weights, args.config)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L18" class="blob-num js-line-number" data-line-number="18"></td>
        <td id="file-yolo_opencv_part2-py-LC18" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L19" class="blob-num js-line-number" data-line-number="19"></td>
        <td id="file-yolo_opencv_part2-py-LC19" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> create input blob </span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L20" class="blob-num js-line-number" data-line-number="20"></td>
        <td id="file-yolo_opencv_part2-py-LC20" class="blob-code blob-code-inner js-file-line">blob <span class="pl-k">=</span> cv2.dnn.blobFromImage(image, scale, (<span class="pl-c1">416</span>,<span class="pl-c1">416</span>), (<span class="pl-c1">0</span>,<span class="pl-c1">0</span>,<span class="pl-c1">0</span>), <span class="pl-c1">True</span>, <span class="pl-v">crop</span><span class="pl-k">=</span><span class="pl-c1">False</span>)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L21" class="blob-num js-line-number" data-line-number="21"></td>
        <td id="file-yolo_opencv_part2-py-LC21" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L22" class="blob-num js-line-number" data-line-number="22"></td>
        <td id="file-yolo_opencv_part2-py-LC22" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> set input blob for the network</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part2-py-L23" class="blob-num js-line-number" data-line-number="23"></td>
        <td id="file-yolo_opencv_part2-py-LC23" class="blob-code blob-code-inner js-file-line">net.setInput(blob)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/arunponnusamy/64a0fcec27fea6abf3ac9f26485b9d6c/raw/a0fa912c99b6cf35d7f0a436084ccddb75a26b0c/yolo_opencv_part2.py" style="float:right">view raw</a>
        <a href="https://gist.github.com/arunponnusamy/64a0fcec27fea6abf3ac9f26485b9d6c#file-yolo_opencv_part2-py">yolo_opencv_part2.py</a>
        hosted with ❤ by <a href="https://github.com/">GitHub</a>
      </div>
    </div>
</div>
</div>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Read the input image and get its width and height. </p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Read the text file containing class names in human readable form and extract the class names to a list.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Generate different colors for different classes to draw bounding boxes. </p>

<code class="col-sm-offset-3 col-sm-6 col-sm-offset-3">net = cv2.dnn.readNet(args.weights, args.config)</code>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Above line reads the weights and config file and creates the network.</p>

<code class="col-sm-offset-3 col-sm-6 col-sm-offset-3"><p>blob = cv2.dnn.blobFromImage(image, scale, (Width,Height), (0,0,0), True, crop=False)</p>
<p>net.setInput(blob)</p></code>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Above lines prepares the input image to run through the deep neural network. </p>

<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Output layer and bounding box
</h2>

<div class="col-sm-offset-3 col-sm-6 col-sm-offset-3">
<script src="./YOLO Object Detection with OpenCV and Python_files/de373e1a579e1107296954c2d9f05b2f.js"></script><link rel="stylesheet" href="./YOLO Object Detection with OpenCV and Python_files/gist-embed-a9a1cf2ca01efd362bfa52312712ae94.css"><div id="gist91006054" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-yolo_opencv_part3-py" class="file">
    

  <div itemprop="text" class="Box-body px-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-yolo_opencv_part3-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-yolo_opencv_part3-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> function to get the output layer names </span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-yolo_opencv_part3-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> in the architecture</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-yolo_opencv_part3-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-k">def</span> <span class="pl-en">get_output_layers</span>(<span class="pl-smi">net</span>):</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-yolo_opencv_part3-py-LC4" class="blob-code blob-code-inner js-file-line">    </td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-yolo_opencv_part3-py-LC5" class="blob-code blob-code-inner js-file-line">    layer_names <span class="pl-k">=</span> net.getLayerNames()</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-yolo_opencv_part3-py-LC6" class="blob-code blob-code-inner js-file-line">    </td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-yolo_opencv_part3-py-LC7" class="blob-code blob-code-inner js-file-line">    output_layers <span class="pl-k">=</span> [layer_names[i[<span class="pl-c1">0</span>] <span class="pl-k">-</span> <span class="pl-c1">1</span>] <span class="pl-k">for</span> i <span class="pl-k">in</span> net.getUnconnectedOutLayers()]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-yolo_opencv_part3-py-LC8" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-yolo_opencv_part3-py-LC9" class="blob-code blob-code-inner js-file-line">    <span class="pl-k">return</span> output_layers</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-yolo_opencv_part3-py-LC10" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-yolo_opencv_part3-py-LC11" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> function to draw bounding box on the detected object with class name</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-yolo_opencv_part3-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-k">def</span> <span class="pl-en">draw_bounding_box</span>(<span class="pl-smi">img</span>, <span class="pl-smi">class_id</span>, <span class="pl-smi">confidence</span>, <span class="pl-smi">x</span>, <span class="pl-smi">y</span>, <span class="pl-smi">x_plus_w</span>, <span class="pl-smi">y_plus_h</span>):</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-yolo_opencv_part3-py-LC13" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-yolo_opencv_part3-py-LC14" class="blob-code blob-code-inner js-file-line">    label <span class="pl-k">=</span> <span class="pl-c1">str</span>(classes[class_id])</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L15" class="blob-num js-line-number" data-line-number="15"></td>
        <td id="file-yolo_opencv_part3-py-LC15" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L16" class="blob-num js-line-number" data-line-number="16"></td>
        <td id="file-yolo_opencv_part3-py-LC16" class="blob-code blob-code-inner js-file-line">    color <span class="pl-k">=</span> <span class="pl-c1">COLORS</span>[class_id]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L17" class="blob-num js-line-number" data-line-number="17"></td>
        <td id="file-yolo_opencv_part3-py-LC17" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L18" class="blob-num js-line-number" data-line-number="18"></td>
        <td id="file-yolo_opencv_part3-py-LC18" class="blob-code blob-code-inner js-file-line">    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, <span class="pl-c1">2</span>)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L19" class="blob-num js-line-number" data-line-number="19"></td>
        <td id="file-yolo_opencv_part3-py-LC19" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part3-py-L20" class="blob-num js-line-number" data-line-number="20"></td>
        <td id="file-yolo_opencv_part3-py-LC20" class="blob-code blob-code-inner js-file-line">    cv2.putText(img, label, (x<span class="pl-k">-</span><span class="pl-c1">10</span>,y<span class="pl-k">-</span><span class="pl-c1">10</span>), cv2.<span class="pl-c1">FONT_HERSHEY_SIMPLEX</span>, <span class="pl-c1">0.5</span>, color, <span class="pl-c1">2</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/arunponnusamy/de373e1a579e1107296954c2d9f05b2f/raw/750124c0fd52739acf7a671f1309c9c8c773314e/yolo_opencv_part3.py" style="float:right">view raw</a>
        <a href="https://gist.github.com/arunponnusamy/de373e1a579e1107296954c2d9f05b2f#file-yolo_opencv_part3-py">yolo_opencv_part3.py</a>
        hosted with ❤ by <a href="https://github.com/">GitHub</a>
      </div>
    </div>
</div>
</div>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Generally in a sequential CNN network there will be only one output layer at the end. In the YOLO v3 architecture we are using there are multiple output layers giving out predictions. <code>get_output_layers() </code>function gives the names of the output layers. An output layer is not connected to any next layer.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3"><code>draw_bounding_box()</code> function draws rectangle over the given predicted region and writes class name over the box. If needed, we can write the confidence value too.</p>

<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Running inference</h2>
<div class="col-sm-offset-3 col-sm-6 col-sm-offset-3">
<script src="./YOLO Object Detection with OpenCV and Python_files/220022a22c7367b38bf5ff95468815b9.js"></script><link rel="stylesheet" href="./YOLO Object Detection with OpenCV and Python_files/gist-embed-a9a1cf2ca01efd362bfa52312712ae94.css"><div id="gist91006632" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-yolo_opencv_part4-py" class="file">
    

  <div itemprop="text" class="Box-body px-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-yolo_opencv_part4-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-yolo_opencv_part4-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> run inference through the network</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-yolo_opencv_part4-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> and gather predictions from output layers</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-yolo_opencv_part4-py-LC3" class="blob-code blob-code-inner js-file-line">outs <span class="pl-k">=</span> net.forward(get_output_layers(net))</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-yolo_opencv_part4-py-LC4" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-yolo_opencv_part4-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> initialization</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-yolo_opencv_part4-py-LC6" class="blob-code blob-code-inner js-file-line">class_ids <span class="pl-k">=</span> []</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-yolo_opencv_part4-py-LC7" class="blob-code blob-code-inner js-file-line">confidences <span class="pl-k">=</span> []</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-yolo_opencv_part4-py-LC8" class="blob-code blob-code-inner js-file-line">boxes <span class="pl-k">=</span> []</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-yolo_opencv_part4-py-LC9" class="blob-code blob-code-inner js-file-line">conf_threshold <span class="pl-k">=</span> <span class="pl-c1">0.5</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-yolo_opencv_part4-py-LC10" class="blob-code blob-code-inner js-file-line">nms_threshold <span class="pl-k">=</span> <span class="pl-c1">0.4</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-yolo_opencv_part4-py-LC11" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-yolo_opencv_part4-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> for each detetion from each output layer </span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-yolo_opencv_part4-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> get the confidence, class id, bounding box params</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-yolo_opencv_part4-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> and ignore weak detections (confidence &lt; 0.5)</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L15" class="blob-num js-line-number" data-line-number="15"></td>
        <td id="file-yolo_opencv_part4-py-LC15" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> out <span class="pl-k">in</span> outs:</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L16" class="blob-num js-line-number" data-line-number="16"></td>
        <td id="file-yolo_opencv_part4-py-LC16" class="blob-code blob-code-inner js-file-line">    <span class="pl-k">for</span> detection <span class="pl-k">in</span> out:</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L17" class="blob-num js-line-number" data-line-number="17"></td>
        <td id="file-yolo_opencv_part4-py-LC17" class="blob-code blob-code-inner js-file-line">        scores <span class="pl-k">=</span> detection[<span class="pl-c1">5</span>:]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L18" class="blob-num js-line-number" data-line-number="18"></td>
        <td id="file-yolo_opencv_part4-py-LC18" class="blob-code blob-code-inner js-file-line">        class_id <span class="pl-k">=</span> np.argmax(scores)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L19" class="blob-num js-line-number" data-line-number="19"></td>
        <td id="file-yolo_opencv_part4-py-LC19" class="blob-code blob-code-inner js-file-line">        confidence <span class="pl-k">=</span> scores[class_id]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L20" class="blob-num js-line-number" data-line-number="20"></td>
        <td id="file-yolo_opencv_part4-py-LC20" class="blob-code blob-code-inner js-file-line">        <span class="pl-k">if</span> confidence <span class="pl-k">&gt;</span> <span class="pl-c1">0.5</span>:</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L21" class="blob-num js-line-number" data-line-number="21"></td>
        <td id="file-yolo_opencv_part4-py-LC21" class="blob-code blob-code-inner js-file-line">            center_x <span class="pl-k">=</span> <span class="pl-c1">int</span>(detection[<span class="pl-c1">0</span>] <span class="pl-k">*</span> Width)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L22" class="blob-num js-line-number" data-line-number="22"></td>
        <td id="file-yolo_opencv_part4-py-LC22" class="blob-code blob-code-inner js-file-line">            center_y <span class="pl-k">=</span> <span class="pl-c1">int</span>(detection[<span class="pl-c1">1</span>] <span class="pl-k">*</span> Height)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L23" class="blob-num js-line-number" data-line-number="23"></td>
        <td id="file-yolo_opencv_part4-py-LC23" class="blob-code blob-code-inner js-file-line">            w <span class="pl-k">=</span> <span class="pl-c1">int</span>(detection[<span class="pl-c1">2</span>] <span class="pl-k">*</span> Width)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L24" class="blob-num js-line-number" data-line-number="24"></td>
        <td id="file-yolo_opencv_part4-py-LC24" class="blob-code blob-code-inner js-file-line">            h <span class="pl-k">=</span> <span class="pl-c1">int</span>(detection[<span class="pl-c1">3</span>] <span class="pl-k">*</span> Height)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L25" class="blob-num js-line-number" data-line-number="25"></td>
        <td id="file-yolo_opencv_part4-py-LC25" class="blob-code blob-code-inner js-file-line">            x <span class="pl-k">=</span> center_x <span class="pl-k">-</span> w <span class="pl-k">/</span> <span class="pl-c1">2</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L26" class="blob-num js-line-number" data-line-number="26"></td>
        <td id="file-yolo_opencv_part4-py-LC26" class="blob-code blob-code-inner js-file-line">            y <span class="pl-k">=</span> center_y <span class="pl-k">-</span> h <span class="pl-k">/</span> <span class="pl-c1">2</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L27" class="blob-num js-line-number" data-line-number="27"></td>
        <td id="file-yolo_opencv_part4-py-LC27" class="blob-code blob-code-inner js-file-line">            class_ids.append(class_id)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L28" class="blob-num js-line-number" data-line-number="28"></td>
        <td id="file-yolo_opencv_part4-py-LC28" class="blob-code blob-code-inner js-file-line">            confidences.append(<span class="pl-c1">float</span>(confidence))</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part4-py-L29" class="blob-num js-line-number" data-line-number="29"></td>
        <td id="file-yolo_opencv_part4-py-LC29" class="blob-code blob-code-inner js-file-line">            boxes.append([x, y, w, h])</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/arunponnusamy/220022a22c7367b38bf5ff95468815b9/raw/3aadaa3d5b259bfe78df2c7ac34a74f79c3dd33a/yolo_opencv_part4.py" style="float:right">view raw</a>
        <a href="https://gist.github.com/arunponnusamy/220022a22c7367b38bf5ff95468815b9#file-yolo_opencv_part4-py">yolo_opencv_part4.py</a>
        hosted with ❤ by <a href="https://github.com/">GitHub</a>
      </div>
    </div>
</div>
</div>

<code class="col-sm-offset-3 col-sm-6 col-sm-offset-3"> outs = net.forward(get_output_layers(net))</code>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Above line is where the exact feed forward through the network happens. Moment of truth. If we don’t specify the output layer names, by default, it will return the predictions only from final output layer. Any intermediate output layer will be ignored.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">We need go through each detection from each output layer to get the class id, confidence and bounding box corners and more importantly ignore the weak detections (detections with low confidence value).</p>

<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Non-max suppression</h2>

<div class="col-sm-offset-3 col-sm-6 col-sm-offset-3">
<script src="./YOLO Object Detection with OpenCV and Python_files/e898be8a55ecee45b1099620cb6a9b5b.js"></script><link rel="stylesheet" href="./YOLO Object Detection with OpenCV and Python_files/gist-embed-a9a1cf2ca01efd362bfa52312712ae94.css"><div id="gist91007483" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-yolo_opencv_part5-py" class="file">
    

  <div itemprop="text" class="Box-body px-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-yolo_opencv_part5-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-yolo_opencv_part5-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> apply non-max suppression</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-yolo_opencv_part5-py-LC2" class="blob-code blob-code-inner js-file-line">indices <span class="pl-k">=</span> cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-yolo_opencv_part5-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-yolo_opencv_part5-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> go through the detections remaining</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-yolo_opencv_part5-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> after nms and draw bounding box</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-yolo_opencv_part5-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> i <span class="pl-k">in</span> indices:</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-yolo_opencv_part5-py-LC7" class="blob-code blob-code-inner js-file-line">    i <span class="pl-k">=</span> i[<span class="pl-c1">0</span>]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-yolo_opencv_part5-py-LC8" class="blob-code blob-code-inner js-file-line">    box <span class="pl-k">=</span> boxes[i]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-yolo_opencv_part5-py-LC9" class="blob-code blob-code-inner js-file-line">    x <span class="pl-k">=</span> box[<span class="pl-c1">0</span>]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-yolo_opencv_part5-py-LC10" class="blob-code blob-code-inner js-file-line">    y <span class="pl-k">=</span> box[<span class="pl-c1">1</span>]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-yolo_opencv_part5-py-LC11" class="blob-code blob-code-inner js-file-line">    w <span class="pl-k">=</span> box[<span class="pl-c1">2</span>]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-yolo_opencv_part5-py-LC12" class="blob-code blob-code-inner js-file-line">    h <span class="pl-k">=</span> box[<span class="pl-c1">3</span>]</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-yolo_opencv_part5-py-LC13" class="blob-code blob-code-inner js-file-line">    </td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-yolo_opencv_part5-py-LC14" class="blob-code blob-code-inner js-file-line">    draw_bounding_box(image, class_ids[i], confidences[i], <span class="pl-c1">round</span>(x), <span class="pl-c1">round</span>(y), <span class="pl-c1">round</span>(x<span class="pl-k">+</span>w), <span class="pl-c1">round</span>(y<span class="pl-k">+</span>h))</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L15" class="blob-num js-line-number" data-line-number="15"></td>
        <td id="file-yolo_opencv_part5-py-LC15" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L16" class="blob-num js-line-number" data-line-number="16"></td>
        <td id="file-yolo_opencv_part5-py-LC16" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> display output image    </span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L17" class="blob-num js-line-number" data-line-number="17"></td>
        <td id="file-yolo_opencv_part5-py-LC17" class="blob-code blob-code-inner js-file-line">cv2.imshow(<span class="pl-s"><span class="pl-pds">"</span>object detection<span class="pl-pds">"</span></span>, image)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L18" class="blob-num js-line-number" data-line-number="18"></td>
        <td id="file-yolo_opencv_part5-py-LC18" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L19" class="blob-num js-line-number" data-line-number="19"></td>
        <td id="file-yolo_opencv_part5-py-LC19" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> wait until any key is pressed</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L20" class="blob-num js-line-number" data-line-number="20"></td>
        <td id="file-yolo_opencv_part5-py-LC20" class="blob-code blob-code-inner js-file-line">cv2.waitKey()</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L21" class="blob-num js-line-number" data-line-number="21"></td>
        <td id="file-yolo_opencv_part5-py-LC21" class="blob-code blob-code-inner js-file-line">    </td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L22" class="blob-num js-line-number" data-line-number="22"></td>
        <td id="file-yolo_opencv_part5-py-LC22" class="blob-code blob-code-inner js-file-line"> <span class="pl-c"><span class="pl-c">#</span> save output image to disk</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L23" class="blob-num js-line-number" data-line-number="23"></td>
        <td id="file-yolo_opencv_part5-py-LC23" class="blob-code blob-code-inner js-file-line">cv2.imwrite(<span class="pl-s"><span class="pl-pds">"</span>object-detection.jpg<span class="pl-pds">"</span></span>, image)</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L24" class="blob-num js-line-number" data-line-number="24"></td>
        <td id="file-yolo_opencv_part5-py-LC24" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L25" class="blob-num js-line-number" data-line-number="25"></td>
        <td id="file-yolo_opencv_part5-py-LC25" class="blob-code blob-code-inner js-file-line"><span class="pl-c"><span class="pl-c">#</span> release resources</span></td>
      </tr>
      <tr>
        <td id="file-yolo_opencv_part5-py-L26" class="blob-num js-line-number" data-line-number="26"></td>
        <td id="file-yolo_opencv_part5-py-LC26" class="blob-code blob-code-inner js-file-line">cv2.destroyAllWindows()</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/arunponnusamy/e898be8a55ecee45b1099620cb6a9b5b/raw/1ff20c1c10f9169c81ba2340810076e436b45fc3/yolo_opencv_part5.py" style="float:right">view raw</a>
        <a href="https://gist.github.com/arunponnusamy/e898be8a55ecee45b1099620cb6a9b5b#file-yolo_opencv_part5-py">yolo_opencv_part5.py</a>
        hosted with ❤ by <a href="https://github.com/">GitHub</a>
      </div>
    </div>
</div>
</div>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Even though we ignored weak detections, there will be lot of duplicate detections with overlapping bounding boxes. Non-max suppression removes boxes with high overlapping.</p>

<img class="col-sm-offset-3 col-sm-6 col-sm-offset-3" src="./YOLO Object Detection with OpenCV and Python_files/gentle_guide_nms.jpg">
<p class="col-sm-offset-4 col-sm-4 col-sm-offset-4" id="source">Source: <a href="https://www.pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/">PyImageSearch</a></p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Finally we look at the detections that are left and draw bounding boxes around them and display the output image.</p>

<img class="col-sm-offset-4 col-sm-4 col-sm-offset-4" src="./YOLO Object Detection with OpenCV and Python_files/object-detection2.jpg">
<p class="col-sm-offset-4 col-sm-4 col-sm-offset-4" id="source"><a href="https://github.com/pjreddie/darknet/blob/master/data/person.jpg">source</a></p>

<img class="col-sm-offset-4 col-sm-4 col-sm-offset-4" src="./YOLO Object Detection with OpenCV and Python_files/object-detection3.jpg">
<p class="col-sm-offset-4 col-sm-4 col-sm-offset-4" id="source"><a href="https://c8.alamy.com/comp/D5E4G0/woman-on-bicycle-waiting-at-stop-sign-to-cross-busy-road-salt-creek-D5E4G0.jpg">source</a></p>

<img class="col-sm-offset-4 col-sm-4 col-sm-offset-4" src="./YOLO Object Detection with OpenCV and Python_files/object-detection4.jpg">

<p class="col-sm-offset-4 col-sm-4 col-sm-offset-4" id="source"><a href="https://pro-rankedboost.netdna-ssl.com/wp-content/uploads/2017/06/PUBG-New-Vehicle.jpg">source</a></p>
<p id="source" class="col-sm-offset-3 col-sm-6 col-sm-offset-3">I do not own the copyright for the images used in this post. Please refer source for copyright info.</p>

<h2 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Summary</h2>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">In this post, we looked at how to use OpenCV dnn module with pre-trained YOLO model to do object detection. We can also train a model to detect objects of our own interest that are not covered in the pre-trained one.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">We have only scratched the surface. There is a lot more to object detection. I will be covering more on object detection in the future including other frameworks like Faster R-CNN and SSD. Be sure to <a href="http://eepurl.com/dtoOc9"> subscribe</a> to get notified when new posts are published.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">That’s all for now. Thanks for reading. I hope this post was useful to get started with object detection. Feel free to share your thoughts in the comments or you can reach out to me on twitter <a href="https://twitter.com/ponnusamy_arun">@ponnusamy_arun</a>.</p>

<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Peace.</p>

<h3 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Update :</h3>
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Checkout the object detection implementation available in <a href="http://cvlib.net/">cvlib</a> which enables detecting common objects in the context through a single function call <code>detect_common_objects()</code>. Give it a shot and let me know your thoughts. Cheers.</p>

<h3 class="col-sm-offset-3 col-sm-6 col-sm-offset-3">Subscribe to newsletter</h3>
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3">If you are finding this blog interesting, consider subscribing to the newsletter to get notified when new posts go live. (Don't worry, I publish only one or two posts per month)</p>
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3"><a href="http://eepurl.com/dtoOc9"> Subscribe</a></p>

<h3 class="col-sm-offset-3 col-sm-6 col-sm-offset-3"><b>Recent posts</b></h3>
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3"><a href="https://www.arunponnusamy.com/cnn-face-detector-dlib.html">CNN based face detector from dlib</a></p>
<p class="col-sm-offset-3 col-sm-6 col-sm-offset-3"><a href="https://www.arunponnusamy.com/deep-learning-setup-macos.html">Setting up deep learning environment the easy way on macOS High Sierra</a></p>


   </div>

</section>

<div id="disqus_thread" class="col-sm-offset-3 col-sm-6 col-sm-offset-3"><iframe id="dsq-app7717" name="dsq-app7717" allowtransparency="true" frameborder="0" scrolling="no" tabindex="0" title="Disqus" width="100%" src="./YOLO Object Detection with OpenCV and Python_files/saved_resource.html" style="width: 1px !important; min-width: 100% !important; border: none !important; overflow: hidden !important; height: 9549px !important;" horizontalscrolling="no" verticalscrolling="no"></iframe></div>
<script class="col-sm-offset-3 col-sm-6 col-sm-offset-3">

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = 'http://arunponnusamy.com/yolo-object-detection-opencv-python.html';  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = 'yolo-object-detection-opencv-python'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://arunponnusamy.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                            

<footer class="col-sm-offset-3 col-sm-6 col-sm-offset-3">
    <div class="row">
        <p class="col-sm-4">© 2018 Arun Ponnusamy</p>
        <ul class="col-sm-8">
            <li class="col-sm-1"><a href="https://github.com/arunponnusamy"><img src="./YOLO Object Detection with OpenCV and Python_files/25231.png"></a></li>  
            <li class="col-sm-1"><a href="https://twitter.com/ponnusamy_arun"><img src="./YOLO Object Detection with OpenCV and Python_files/Twitter_bird_logo_2012.svg"></a></li>  
            <li class="col-sm-1"><a href="https://www.linkedin.com/in/arun-ponnusamy/"><img src="./YOLO Object Detection with OpenCV and Python_files/logotipo-oficial-linkedin-2014.png"></a></li>
            <li class="col-sm-1"><a href="https://www.quora.com/profile/Arun-Ponnusamy-2"><img src="./YOLO Object Detection with OpenCV and Python_files/quora.png"></a></li>
            <li class="col-sm-1" id="medium"><a href="https://medium.com/@arunponnusamy"><img src="./YOLO Object Detection with OpenCV and Python_files/5841c47ba6515b1e0ad75aa3.png"></a></li>  
    </ul></div>
</footer>




<iframe style="display: none;" src="./YOLO Object Detection with OpenCV and Python_files/saved_resource(1).html"></iframe></body></html>